{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3529a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import yaml\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import ndcg_score, average_precision_score, precision_score, recall_score\n",
    "\n",
    "import spotipy \n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from surprise import NMF, SVD, SVDpp, KNNBasic, KNNWithMeans, KNNWithZScore, CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import surprise\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from recommenders.models.surprise.surprise_utils import predict, compute_ranking_predictions\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from typing import List\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a25d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POTREBNO IZMJENIT PUTANJU!!!!\n",
    "\n",
    "#PREUZIMANJE PODATAKA GENERIRANIH IZ SPOTIFY\n",
    "\n",
    "playlist_tracks_df_1 = pd.read_pickle(r\"C:\\Users\\Ivan\\PycharmProjects\\sars4\\sars4\\spotify\\playlist_tracks.pkl\")\n",
    "playlist_tracks_df_2 = pd.read_pickle(r\"C:\\Users\\Ivan\\PycharmProjects\\sars8\\spotify\\playlist_tracks_2.pkl\")\n",
    "playlist_tracks_df_3 = pd.read_pickle(r\"C:\\Users\\Ivan\\PycharmProjects\\sars10\\spotify\\playlist_tracks_3.pkl\")\n",
    "playlist_tracks_df = pd.concat([playlist_tracks_df_1,playlist_tracks_df_2, playlist_tracks_df_3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787ea665",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_tracks_df['event_strength'] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4a9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIRANJE DATAFRAMEA GDJE JE DEFINIRAN SVAKI PAR (KORISNIK-STVAR)->OCJENA\n",
    "\n",
    "playlist_tracks_df['event_strength'] = 0  \n",
    "user_set = playlist_tracks_df['playlist_id'].unique()\n",
    "item_set=playlist_tracks_df['id'].unique()\n",
    "ptm = pd.DataFrame(columns=[\"userID\", \"itemID\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0d0e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [22:45<00:00,  9.16s/it]\n"
     ]
    }
   ],
   "source": [
    "#KOMBINIRAJ PAROVE KORISNIK-STVAR U DATAFRAME OBLIKA-(KORISNIK-STVAR->AKO JE KORISNIK IMAO INTERAKCIJU SA STVARI - 1, ELSE - 0)\n",
    "\n",
    "ptm_dict={}\n",
    "for user in tqdm(user_set):\n",
    "    user_item_proto=playlist_tracks_df[playlist_tracks_df['playlist_id']==user]['id']\n",
    "    \n",
    "    ptm_dict[user]=pd.DataFrame(pd.Series({\"userID\": user, \"itemID\": item, \"rating\": 1}) \n",
    "                    if(user_item_proto.str.contains(item, case=False).any())\n",
    "                    else (pd.Series({\"userID\": user, \"itemID\": item, \"rating\": 0}))\n",
    "                    for item in item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e6f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [00:02<00:00, 63.13it/s]\n"
     ]
    }
   ],
   "source": [
    "#SPREMI GENERIRANI DICTIONARY U ZAJEDNICKI DATAFRAME\n",
    "\n",
    "ptm=pd.DataFrame(columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "\n",
    "for elem in tqdm(ptm_dict):\n",
    "    if len(ptm)==0:\n",
    "        ptm=ptm_dict[elem]\n",
    "    else:\n",
    "        ptm = pd.concat([ptm, ptm_dict[elem]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a173fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIRAJ READER OD 0-1 S KOJIM CE SE PTM PRENIJET NA DATA\n",
    "#DATA SE UČI NA ALGORITMU SVD()\n",
    "\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "data = Dataset.load_from_df(ptm, reader)\n",
    "algo = SVD()\n",
    "algo.fit(data.build_full_trainset())\n",
    "my_recs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76cdd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [08:56<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "source": [
    "#RADI PREDVIĐANJA\n",
    "\n",
    "results_SVD_dict={}\n",
    "for user in tqdm(user_set):\n",
    "    results_SVD_dict[user]=pd.DataFrame(pd.Series({\"userID\": user, \"itemID\": item, \"pred\": algo.predict(uid=user,iid=item).est})\n",
    "                                                for item in item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a27649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [00:02<00:00, 59.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#PRENESI PREDVIĐANJA IZ DICTIONARYJA U ZAJEDNIČKI DATAFRAME\n",
    "\n",
    "results_SVD=pd.DataFrame(columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "for elem in tqdm(results_SVD_dict):\n",
    "    if len(results_SVD)==0:\n",
    "        results_SVD=results_SVD_dict[elem]\n",
    "    else:\n",
    "        results_SVD = pd.concat([results_SVD, results_SVD_dict[elem]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d280e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPAJANJE MATRICA USER-ITEM-RATING-PREDICTION\n",
    "\n",
    "ui_rating_prediction_df = ptm.merge(results_SVD, on=['userID', 'itemID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a98524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 903.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE 100TH:   0.05117256954866526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#IZRACUNAJ PROSJECNU VRIJEDNOST STOTOG ELEMENTA\n",
    "\n",
    "average_100th_list=[]\n",
    "for user in tqdm(results_SVD_dict):\n",
    "    average_100th_list.append(results_SVD_dict[user]['pred'].sort_values(ascending=False).iloc[99])\n",
    "average_100th=sum(average_100th_list)/len(average_100th_list)\n",
    "print(\"AVERAGE 100TH:  \",average_100th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d8d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 745.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#Izračunaj koliko se koja pjesma ponavlja u preporukama za sve korisnike\n",
    "\n",
    "preds_dict_rec_100={}\n",
    "items_count_dict={}\n",
    "for item in playlist_tracks_df.index:\n",
    "    items_count_dict[item]=0\n",
    "\n",
    "for user in tqdm(results_SVD_dict):\n",
    "    preds_dict_rec_100[user]=results_SVD_dict[user]['pred'].sort_values(ascending=False).head(99)\n",
    "    for item in preds_dict_rec_100[user].index:\n",
    "        items_count_dict[item]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d0d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-\n"
     ]
    }
   ],
   "source": [
    "print(\"CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "179f57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.0994  0.1004  0.1017  0.1009  0.0968  0.0954  0.0979  0.0995  0.0974  0.0969  0.0986  0.0019  \n",
      "Fit time          195.78  223.66  221.18  229.93  229.64  244.13  229.02  188.85  182.71  181.08  212.60  21.87   \n",
      "Test time         17.09   3.92    2.40    5.08    4.09    3.47    3.89    3.66    2.00    3.20    4.88    4.15    \n",
      "CV cross_validate RMSE: 0.09863147379324289\n"
     ]
    }
   ],
   "source": [
    "average_rmse_cv1=cross_validate(algo, data, measures=['RMSE'], cv=10, verbose=True)\n",
    "print('CV cross_validate RMSE: ' + str(sum(average_rmse_cv1['test_rmse']) / len(average_rmse_cv1['test_rmse'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4711c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MAE of algorithm SVD on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "MAE (testset)     0.0195  0.0197  0.0200  0.0202  0.0200  0.0199  0.0205  0.0196  0.0196  0.0197  0.0199  0.0003  \n",
      "Fit time          175.31  122.38  120.84  111.04  103.96  108.99  106.06  107.31  106.15  108.93  117.10  20.27   \n",
      "Test time         1.73    2.05    2.35    1.20    1.73    1.83    1.20    1.88    1.17    1.15    1.63    0.40    \n",
      "CV cross_validate MAE: 0.019879080528878313\n"
     ]
    }
   ],
   "source": [
    "average_mae_cv1=cross_validate(algo, data, measures=['MAE'], cv=10, verbose=True)\n",
    "print('CV cross_validate MAE: ' + str(sum(average_mae_cv1['test_mae']) / len(average_mae_cv1['test_mae'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe6a638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [18:15, 109.56s/it]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "algo_test = SVD()\n",
    "rmse_results_cv2=[]\n",
    "mae_results_cv2=[]\n",
    "precision_results_cv_micro=[]\n",
    "precision_results_cv_macro=[]\n",
    "precision_results_cv_weighted=[]\n",
    "recall_results_cv_micro=[]\n",
    "recall_results_cv_macro=[]\n",
    "recall_results_cv_weighted=[]\n",
    "\n",
    "map_results_cv = []\n",
    "ndcg_results_cv = []\n",
    "\n",
    "for trainset, testset in tqdm(kf.split(data)):\n",
    "    algo_test.fit(trainset)                      #NAUCI NA TRAINSETU         \n",
    "    predictions = algo_test.test(testset)        #NAPRAVI PREDVIDANJA NA TESTSETU\n",
    "    \n",
    "    dframe = pd.DataFrame(predictions, columns=[\"uid\", \"iid\", \"true_r\", \"est\", \"details\"])   #STAVI U ISTI DATASET\n",
    "    \n",
    "    #EVALUACIJA\n",
    "    \n",
    "    rmse_results_cv2.append(sqrt(mean_squared_error(dframe['est'], dframe['true_r'])))     \n",
    "    mae_results_cv2.append((mean_absolute_error(dframe['est'], dframe['true_r'])))\n",
    "    \n",
    "    average_map = average_precision_score(dframe['true_r'].values, dframe['est'].values)\n",
    "    map_results_cv.append(average_map)\n",
    "        \n",
    "    average_ndcg=ndcg_score(dframe['true_r'].values.reshape(1, -1), dframe['est'].values.reshape(1, -1))\n",
    "    ndcg_results_cv.append(average_ndcg)\n",
    "    \n",
    "    df=dframe.copy()\n",
    "    df.loc[df['est']>=average_100th, 'est']=1\n",
    "    df.loc[df['est']<average_100th, 'est']=0\n",
    "\n",
    "    precision_results_cv_micro.append(precision_score(df['true_r'], df['est'], average='micro'))\n",
    "    recall_results_cv_micro.append(recall_score(df['true_r'], df['est'], average='micro'))\n",
    "    \n",
    "    precision_results_cv_macro.append(precision_score(df['true_r'], df['est'], average='macro'))\n",
    "    recall_results_cv_macro.append(recall_score(df['true_r'], df['est'], average='macro'))\n",
    "    \n",
    "    precision_results_cv_weighted.append(precision_score(df['true_r'], df['est'], average='weighted'))\n",
    "    recall_results_cv_weighted.append(recall_score(df['true_r'], df['est'], average='weighted'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c81202c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV SKLEARN.METRICS RMSE SCORE:     0.09865669108115671\n",
      "CV SKLEARN.METRICS MAE SCORE:     0.019971402832553723\n",
      "CV SKLEARN.METRICS MAP SCORE:     0.038646456824834495\n",
      "CV SKLEARN.METRICS NDCG SCORE:     0.6205682811164819\n",
      "CV SKLEARN.METRICS PRECISION SCORE: micro:   0.9700038056264717 , macro:   0.5328528816423982 ,weighted:    0.9825176835246895\n",
      "CV SKLEARN.METRICS RECALL SCORE:     micro:   0.9700038056264717 , macro:   0.577007820249823 ,weighted:    0.9700038056264717\n",
      "CV SKLEARN.METRICS F1:    0.9700038056264717 | 0.5540520161244067 | 0.9762206433165364\n"
     ]
    }
   ],
   "source": [
    "mean_rmse_score_cv=np.mean(rmse_results_cv2)\n",
    "mean_mae_score_cv=np.mean(mae_results_cv2)\n",
    "mean_precision_score_cv_micro=np.mean(precision_results_cv_micro)\n",
    "mean_recall_score_cv_micro=np.mean(recall_results_cv_micro)\n",
    "mean_precision_score_cv_macro=np.mean(precision_results_cv_macro)\n",
    "mean_recall_score_cv_macro=np.mean(recall_results_cv_macro)\n",
    "mean_precision_score_cv_weighted=np.mean(precision_results_cv_weighted)\n",
    "mean_recall_score_cv_weighted=np.mean(recall_results_cv_weighted)\n",
    "mean_map_score_cv = np.mean(map_results_cv)\n",
    "mean_ndcg_score_cv = np.mean(ndcg_results_cv)\n",
    "f1_score_cv_micro=(2*mean_precision_score_cv_micro*mean_recall_score_cv_micro)/(mean_precision_score_cv_micro+mean_recall_score_cv_micro)\n",
    "f1_score_cv_macro=(2*mean_precision_score_cv_macro*mean_recall_score_cv_macro)/(mean_precision_score_cv_macro+mean_recall_score_cv_macro)\n",
    "f1_score_cv_weighted=(2*mean_precision_score_cv_weighted*mean_recall_score_cv_weighted)/(mean_precision_score_cv_weighted+mean_recall_score_cv_weighted)\n",
    "\n",
    "print(\"CV SKLEARN.METRICS RMSE SCORE:    \",mean_rmse_score_cv)\n",
    "print(\"CV SKLEARN.METRICS MAE SCORE:    \",mean_mae_score_cv)\n",
    "\n",
    "print(\"CV SKLEARN.METRICS MAP SCORE:    \", mean_map_score_cv)\n",
    "print(\"CV SKLEARN.METRICS NDCG SCORE:    \", mean_ndcg_score_cv)\n",
    "\n",
    "print(\"CV SKLEARN.METRICS PRECISION SCORE:\",'micro:  ',mean_precision_score_cv_micro, ', macro:  ',\n",
    "                      mean_precision_score_cv_macro,',weighted:   ',mean_precision_score_cv_weighted)\n",
    "\n",
    "print(\"CV SKLEARN.METRICS RECALL SCORE:    \",'micro:  ', mean_recall_score_cv_micro, ', macro:  ',\n",
    "                              mean_recall_score_cv_macro,',weighted:   ', mean_recall_score_cv_weighted)\n",
    "\n",
    "print(\"CV SKLEARN.METRICS F1:   \", f1_score_cv_micro,\"|\",\n",
    "                      f1_score_cv_macro, \"|\", f1_score_cv_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b4168e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddb57e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN-TEST SKLEARN.METRICS RMSE:    0.09912246104351213\n",
      "TRAIN-TEST SKLEARN.METRICS MAE: 0.020140474545661164\n",
      "TRAIN-TEST SKLEARN.METRICS NDCG: 0.6466572296559775\n",
      "TRAIN-TEST SKLEARN.METRICS MAP: 0.03754100814274393\n",
      "TRAIN-TEST SKLEARN.METRICS PRECISION SCORE:  0.9698571895781096 0.5313939478476333 0.9822545685792448\n",
      "TRAIN-TEST SKLEARN.METRICS RECALL SCORE:    0.9698571895781096 0.5726490810513785 0.9698571895781096\n",
      "TRAIN-TEST SKLEARN.METRICS F1:    0.9698571895781096 | 0.5512507174918203 | 0.9760165127346512\n"
     ]
    }
   ],
   "source": [
    "trainset_tt, testset_tt = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "#PONAVLJANJE ISTOG PROCESA KAO NA CV SKLEARN.METRICS\n",
    "\n",
    "algo_tt = SVD()\n",
    "algo_tt.fit(trainset_tt)\n",
    "predictions_tt = algo_tt.test(testset_tt)\n",
    "\n",
    "dframe_tt = pd.DataFrame(predictions_tt, columns=[\"uid\", \"iid\", \"true_r\", \"est\", \"details\"])\n",
    "\n",
    "#EVALUACIJA\n",
    "\n",
    "average_rmse_TT=sqrt(mean_squared_error(dframe_tt['est'], dframe_tt['true_r']))\n",
    "average_mae_TT=(mean_absolute_error(dframe_tt['est'], dframe_tt['true_r']))\n",
    "average_ndcg=ndcg_score(dframe_tt['true_r'].values.reshape(1, -1), dframe_tt['est'].values.reshape(1, -1))\n",
    "average_map=average_precision_score(dframe_tt['true_r'].values, dframe_tt['est'].values)\n",
    "\n",
    "df=dframe_tt.copy()\n",
    "df.loc[df['est']>=average_100th, 'est']=1\n",
    "df.loc[df['est']<average_100th, 'est']=0\n",
    "\n",
    "average_precision_micro=(precision_score(df['true_r'], df['est'], average='micro'))\n",
    "average_recall_micro=(recall_score(df['true_r'], df['est'], average='micro'))\n",
    "average_precision_macro=(precision_score(df['true_r'], df['est'], average='macro'))\n",
    "average_recall_macro=(recall_score(df['true_r'], df['est'], average='macro'))\n",
    "average_precision_weighted=(precision_score(df['true_r'], df['est'], average='weighted'))\n",
    "average_recall_weighted=(recall_score(df['true_r'], df['est'], average='weighted'))\n",
    "f1_score_micro=(2*average_precision_micro*average_recall_micro)/(average_precision_micro+average_recall_micro)\n",
    "f1_score_macro=(2*average_precision_macro*average_recall_macro)/(average_precision_macro+average_recall_macro)\n",
    "f1_score_weighted=(2*average_precision_weighted*average_recall_weighted)/(average_precision_weighted+average_recall_weighted)\n",
    "\n",
    "\n",
    "print('TRAIN-TEST SKLEARN.METRICS RMSE:   ', average_rmse_TT)\n",
    "print('TRAIN-TEST SKLEARN.METRICS MAE: ' + str(average_mae_TT))\n",
    "print('TRAIN-TEST SKLEARN.METRICS NDCG: ' + str(average_ndcg))\n",
    "print('TRAIN-TEST SKLEARN.METRICS MAP: ' + str(average_map))\n",
    "print(\"TRAIN-TEST SKLEARN.METRICS PRECISION SCORE: \",average_precision_micro,\n",
    "      average_precision_macro, average_precision_weighted)\n",
    "print(\"TRAIN-TEST SKLEARN.METRICS RECALL SCORE:   \",average_recall_micro, average_recall_macro, average_recall_weighted) \n",
    "print(\"TRAIN-TEST SKLEARN.METRICS F1:   \", f1_score_micro,\"|\",\n",
    "                      f1_score_macro, \"|\", f1_score_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e43eb209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION-NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION\n"
     ]
    }
   ],
   "source": [
    "print(\"NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION-NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2fb6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOVELTY SCORE:    6.131760118408787\n"
     ]
    }
   ],
   "source": [
    "#RECMETRICS NOVELTY\n",
    "def novelty(predicted: dict, pop: dict, u: int, n: int) -> (float, list):\n",
    "    \n",
    "    mean_self_information = []\n",
    "    k = 0\n",
    "    for pred100 in predicted: \n",
    "        self_information = 0\n",
    "        k += 1\n",
    "        for track_index in predicted[pred100].index:\n",
    "            self_information += np.sum(-np.log2(pop[track_index]/u))\n",
    "        mean_self_information.append(self_information/n)\n",
    "    novelty = sum(mean_self_information)/k\n",
    "    return novelty, mean_self_information\n",
    "    \n",
    "test_users = len(playlist_tracks_df) \n",
    "test_recs_per_user = 100\n",
    "\n",
    "novelty_score, _ = novelty(\n",
    "            predicted = preds_dict_rec_100,#predicted data\n",
    "            pop = items_count_dict, #test data\n",
    "            u = test_users, #broj korisnika\n",
    "            n = test_recs_per_user #broj testnih recorda\n",
    ")\n",
    "\n",
    "print(\"NOVELTY SCORE:   \",novelty_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7699c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATALOG COVERAGE SCORE:    0.01\n"
     ]
    }
   ],
   "source": [
    "#RECMETRICS CATALOG COVERAGE\n",
    "\n",
    "def catalog_coverage(catalog: dict) -> float:\n",
    "    sum_non_zero=0\n",
    "    for elem in catalog:\n",
    "        if(catalog[elem]!=0):\n",
    "            sum_non_zero+=1\n",
    "    catalog_coverage = round(sum_non_zero/(len(catalog)*1.0),2)\n",
    "    return catalog_coverage\n",
    "catalog_coverage = catalog_coverage(\n",
    "    catalog = items_count_dict, #test data\n",
    ")\n",
    "\n",
    "print(\"CATALOG COVERAGE SCORE:   \",catalog_coverage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4821114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONALIZATION SCORE:     0.04328703321992067\n"
     ]
    }
   ],
   "source": [
    "#RECMETRICS PERSONALIZATION\n",
    "\n",
    "def personalization(predicted: List[list]) -> float:\n",
    "\n",
    "    def make_rec_matrix(predicted: List[list]) -> sp.csr_matrix:\n",
    "        df = pd.DataFrame(data=predicted).reset_index().melt(\n",
    "            id_vars='index', value_name='item',\n",
    "        )\n",
    "        df = df[['index', 'item']].pivot(index='index', columns='item', values='item')\n",
    "        df = pd.notna(df)*1\n",
    "        rec_matrix = sp.csr_matrix(df.values)\n",
    "        return rec_matrix\n",
    "\n",
    "    #create matrix for recommendations\n",
    "    predicted = np.array(predicted)\n",
    "    rec_matrix_sparse = make_rec_matrix(predicted)\n",
    "\n",
    "    #calculate similarity for every user's recommendation list\n",
    "    similarity = cosine_similarity(X=rec_matrix_sparse, dense_output=False)\n",
    "\n",
    "    #calculate average similarity\n",
    "    dim = similarity.shape[0]\n",
    "    personalization = (similarity.sum() - dim) / (dim * (dim - 1))\n",
    "    return 1-personalization\n",
    "\n",
    "pred100_list = [preds_dict_rec_100[playlist].index.tolist() for playlist in preds_dict_rec_100]\n",
    "\n",
    "# WHEN metrics.personalization is run\n",
    "personalization_score =personalization(\n",
    "    predicted=pred100_list)\n",
    "\n",
    "# THEN the personalization score should be within the expected value\n",
    "print(\"PERSONALIZATION SCORE:    \",personalization_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bd99fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-List Diversity Score: 0.06154516282433993\n"
     ]
    }
   ],
   "source": [
    "#RECMETRICS DIVERSITY\n",
    "#PRESJEK/UNIJA\n",
    "\n",
    "def jaccard_similarity(dframe, average_100th):\n",
    "    index_rating = dframe[dframe['rating']==0].index\n",
    "    index_pred = dframe[dframe['pred']>average_100th].index\n",
    "    intersection_size = len(index_rating[index_rating.isin(index_pred)])\n",
    "    union_size = len(index_rating.union(index_pred))\n",
    "    return intersection_size / union_size if union_size != 0 else 0.0\n",
    "\n",
    "def inter_list_diversity(dframe, average_100th):\n",
    "    length_frame = len(dframe)\n",
    "    pairwise_similarities = []    \n",
    "    similarity = jaccard_similarity(dframe, average_100th)    \n",
    "    return similarity\n",
    "\n",
    "diversity_score = inter_list_diversity(ui_rating_prediction_df,average_100th)\n",
    "print(\"Inter-List Diversity Score:\", diversity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237f90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
