{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e45fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import yaml\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import ndcg_score, average_precision_score, precision_score, recall_score\n",
    "\n",
    "import spotipy \n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from surprise import NMF, SVD, SVDpp, KNNBasic, KNNWithMeans, KNNWithZScore, CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import surprise\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from recommenders.models.surprise.surprise_utils import predict, compute_ranking_predictions\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from typing import List\n",
    "from math import sqrt\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b009c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POTREBNO IZMJENIT PUTANJU!!!!\n",
    "#PREUZIMANJE PODATAKA GENERIRANIH IZ SPOTIFY\n",
    "\n",
    "playlist_tracks_df_1 = pd.read_pickle(r\"C:\\Users\\Ivan\\PycharmProjects\\sars4\\sars4\\spotify\\playlist_tracks.pkl\")\n",
    "playlist_tracks_df_2 = pd.read_pickle(r\"C:\\Users\\Ivan\\PycharmProjects\\sars8\\spotify\\playlist_tracks_2.pkl\")\n",
    "playlist_tracks_df_3 = pd.read_pickle(r\"C:\\Users\\Ivan\\PycharmProjects\\sars10\\spotify\\playlist_tracks_3.pkl\")\n",
    "playlist_tracks_df = pd.concat([playlist_tracks_df_1,playlist_tracks_df_2, playlist_tracks_df_3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210c6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_tracks_df['event_strength'] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55367e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIRANJE DATAFRAMEA GDJE JE DEFINIRAN SVAKI PAR (KORISNIK-STVAR)->OCJENA\n",
    "\n",
    "playlist_tracks_df['event_strength'] = 0  \n",
    "user_set = playlist_tracks_df['playlist_id'].unique()\n",
    "item_set=playlist_tracks_df['id'].unique()\n",
    "ptm = pd.DataFrame(columns=[\"userID\", \"itemID\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42caf322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [30:41<00:00, 12.36s/it]\n"
     ]
    }
   ],
   "source": [
    "#KOMBINIRAJ PAROVE KORISNIK-STVAR U DATAFRAME OBLIKA-(KORISNIK-STVAR->AKO JE KORISNIK IMAO INTERAKCIJU SA STVARI - 1, ELSE - 0)\n",
    "\n",
    "ptm_dict={}\n",
    "for user in tqdm(user_set):\n",
    "    user_item_proto=playlist_tracks_df[playlist_tracks_df['playlist_id']==user]['id']\n",
    "    ptm_dict[user]=pd.DataFrame(pd.Series({\"userID\": user, \"itemID\": item, \"rating\": 1}) \n",
    "                    if(user_item_proto.str.contains(item, case=False).any())\n",
    "                    else (pd.Series({\"userID\": user, \"itemID\": item, \"rating\": 0}))\n",
    "                    for item in item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51807eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [00:03<00:00, 41.47it/s]\n"
     ]
    }
   ],
   "source": [
    "#SPREMI GENERIRANI DICTIONARY U ZAJEDNICKI DATAFRAME\n",
    "\n",
    "ptm=pd.DataFrame(columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "for elem in tqdm(ptm_dict):\n",
    "    if len(ptm)==0:\n",
    "        ptm=ptm_dict[elem]\n",
    "    else:\n",
    "        ptm = pd.concat([ptm, ptm_dict[elem]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b049d8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#DEFINIRAJ READER OD 0-1 S KOJIM CE SE PTM PRENIJET NA DATA\n",
    "#DATA SE UČI NA ALGORITMU KNNBasic()\n",
    "\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "data = Dataset.load_from_df(ptm, reader)\n",
    "algo = KNNBasic()\n",
    "algo.fit(data.build_full_trainset())\n",
    "my_recs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed7addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [18:21<00:00,  7.39s/it]\n"
     ]
    }
   ],
   "source": [
    "#RADI PREDVIĐANJA\n",
    "\n",
    "results_KNN_dict={}\n",
    "for user in tqdm(user_set):\n",
    "    results_KNN_dict[user]=pd.DataFrame(pd.Series({\"userID\": user, \"itemID\": item, \"pred\": algo.predict(uid=user,iid=item).est})\n",
    "                                                for item in item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e78041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [00:02<00:00, 66.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#PRENESI PREDVIĐANJA IZ DICTIONARYJA U ZAJEDNIČKI DATAFRAME\n",
    "\n",
    "results_KNN=pd.DataFrame(columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "for elem in tqdm(results_KNN_dict):\n",
    "    if len(results_KNN)==0:\n",
    "        results_KNN=results_KNN_dict[elem]\n",
    "    else:\n",
    "        results_KNN = pd.concat([results_KNN, results_KNN_dict[elem]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f80d3490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 1733.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE 100TH:   0.04102484896153723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#IZRACUNAJ PROSJECNU VRIJEDNOST STOTOG ELEMENTA\n",
    "\n",
    "average_100th_list=[]\n",
    "for user in tqdm(results_KNN_dict):\n",
    "    average_100th_list.append(results_KNN_dict[user]['pred'].sort_values(ascending=False).iloc[99])\n",
    "average_100th=sum(average_100th_list)/len(average_100th_list)\n",
    "print(\"AVERAGE 100TH:  \",average_100th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84bf333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 1263.13it/s]\n"
     ]
    }
   ],
   "source": [
    "#Izračunaj koliko se koja pjesma ponavlja u preporukama za sve korisnike\n",
    "\n",
    "preds_dict_rec_100={}\n",
    "items_count_dict={}\n",
    "for item in playlist_tracks_df.index:\n",
    "    items_count_dict[item]=0\n",
    "\n",
    "for user in tqdm(results_KNN_dict):\n",
    "    preds_dict_rec_100[user]=results_KNN_dict[user]['pred'].sort_values(ascending=False).head(99)\n",
    "    for item in preds_dict_rec_100[user].index:\n",
    "        items_count_dict[item]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6821b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPAJANJE MATRICA USER-ITEM-RATING-PREDICTION\n",
    "\n",
    "ui_rating_prediction_df = ptm.merge(results_KNN, on=['userID', 'itemID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f47129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-\n"
     ]
    }
   ],
   "source": [
    "print(\"CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-CROSS VALIDATION-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dba5dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.0983  0.0998  0.1006  0.0991  0.0984  0.0990  0.0961  0.0990  0.0995  0.0989  0.0989  0.0011  \n",
      "Fit time          10.13   10.45   9.23    9.26    8.62    8.40    8.48    9.37    8.74    8.74    9.14    0.66    \n",
      "Test time         73.48   57.08   54.30   55.42   53.20   52.36   53.83   52.48   51.15   52.56   55.59   6.18    \n",
      "CV CROSS_VALIDATE RMSE: 0.09886679466098401\n"
     ]
    }
   ],
   "source": [
    "average_rmse=cross_validate(algo, data, measures=['RMSE'], cv=10, verbose=True)\n",
    "print('CV CROSS_VALIDATE RMSE: ' + str(sum(average_rmse['test_rmse']) / len(average_rmse['test_rmse'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12904627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating MAE of algorithm KNNBasic on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "MAE (testset)     0.0130  0.0128  0.0129  0.0128  0.0126  0.0130  0.0135  0.0131  0.0135  0.0129  0.0130  0.0003  \n",
      "Fit time          8.32    8.41    9.61    5.33    5.49    5.24    5.42    5.26    5.27    5.29    6.36    1.62    \n",
      "Test time         52.31   51.91   39.14   33.08   34.05   34.77   33.60   33.71   34.39   33.25   38.02   7.23    \n",
      "CV CROSS_VALIDATE MAE: 0.012977049605823396\n"
     ]
    }
   ],
   "source": [
    "average_mae=cross_validate(algo, data, measures=['MAE'], cv=10, verbose=True)\n",
    "print('CV CROSS_VALIDATE MAE: ' + str(sum(average_mae['test_mae']) / len(average_mae['test_mae'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bcdedcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:30, 30.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:00, 30.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:36, 32.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:29, 40.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [03:21, 44.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [04:40, 56.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [06:13, 68.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [07:37, 73.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [08:53, 74.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [10:08, 60.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV SKLEARN.METRICS RMSE:     0.09887553367023426\n",
      "CV SKLEARN.METRICS MAE:     0.012978723476730597\n",
      "CV SKLEARN.METRICS MAP:     0.037102587416326355\n",
      "CV SKLEARN.METRICS NDCG:     0.6181540194540517\n",
      "CV SKLEARN.METRICS PRECISION:     0.9744437223556288 | 0.5331369800598487 | 0.9821965098925025\n",
      "CV SKLEARN.METRICS RECALL:     0.9744437223556288 | 0.5609414981959416 | 0.9744437223556288\n",
      "CV SKLEARN.METRICS F1:    0.9744437223556288 | 0.5466859321009565 | 0.9783047567049958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "algo_test = KNNBasic()\n",
    "map_results_cv = []\n",
    "ndcg_results_cv = []\n",
    "rmse_list_cv2=[]\n",
    "mae_list_cv2=[]\n",
    "\n",
    "precision_results_cv_micro = []\n",
    "precision_results_cv_macro = []\n",
    "precision_results_cv_weighted = []\n",
    "recall_results_cv_micro = []\n",
    "recall_results_cv_macro = []\n",
    "recall_results_cv_weighted = []\n",
    "\n",
    "for trainset, testset in tqdm(kf.split(data)):\n",
    "    \n",
    "    #SAMO ZA JEDNOG ILI ZA SVE KORISNIKE\n",
    "    \n",
    "    algo_test.fit(trainset)                   #UCENJE\n",
    "    predictions = algo_test.test(testset)     #PREDVIDANJE\n",
    "    dframe = pd.DataFrame(predictions, columns=[\"uid\", \"iid\", \"true_r\", \"est\", \"details\"])\n",
    "    \n",
    "    #EVALUACIJA\n",
    "    \n",
    "    rmse_list_cv2.append(sqrt(mean_squared_error(dframe['est'], dframe['true_r'])))\n",
    "    mae_list_cv2.append((mean_absolute_error(dframe['est'], dframe['true_r'])))\n",
    "    \n",
    "    average_map = average_precision_score(dframe['true_r'].values, dframe['est'].values)\n",
    "    map_results_cv.append(average_map)\n",
    "        \n",
    "    average_ndcg=ndcg_score(dframe['true_r'].values.reshape(1, -1), dframe['est'].values.reshape(1, -1))\n",
    "    ndcg_results_cv.append(average_ndcg)\n",
    "    \n",
    "    df=dframe.copy()\n",
    "    df.loc[df['est']>=average_100th, 'est']=1\n",
    "    df.loc[df['est']<average_100th, 'est']=0\n",
    "    \n",
    "    precision_results_cv_micro.append(precision_score(df['true_r'], df['est'], average='micro'))\n",
    "    recall_results_cv_micro.append(recall_score(df['true_r'], df['est'], average='micro'))\n",
    "    \n",
    "    precision_results_cv_macro.append(precision_score(df['true_r'], df['est'], average='macro'))\n",
    "    recall_results_cv_macro.append(recall_score(df['true_r'], df['est'], average='macro'))\n",
    "    \n",
    "    precision_results_cv_weighted.append(precision_score(df['true_r'], df['est'], average='weighted'))\n",
    "    recall_results_cv_weighted.append(recall_score(df['true_r'], df['est'], average='weighted'))\n",
    "\n",
    "mean_rmse_score_cv=np.mean(rmse_list_cv2)\n",
    "mean_mae_score_cv=np.mean(mae_list_cv2)    \n",
    "mean_map_score_cv = np.mean(map_results_cv)\n",
    "mean_ndcg_score_cv = np.mean(ndcg_results_cv)\n",
    "\n",
    "mean_precision_score_cv_micro=np.mean(precision_results_cv_micro)\n",
    "mean_recall_score_cv_micro=np.mean(recall_results_cv_micro)\n",
    "\n",
    "mean_precision_score_cv_macro=np.mean(precision_results_cv_macro)\n",
    "mean_recall_score_cv_macro=np.mean(recall_results_cv_macro)\n",
    "\n",
    "mean_precision_score_cv_weighted=np.mean(precision_results_cv_weighted)\n",
    "mean_recall_score_cv_weighted=np.mean(recall_results_cv_weighted)\n",
    "\n",
    "f1_score_cv_micro=(2*mean_precision_score_cv_micro*mean_recall_score_cv_micro)/(mean_precision_score_cv_micro+mean_recall_score_cv_micro)\n",
    "f1_score_cv_macro=(2*mean_precision_score_cv_macro*mean_recall_score_cv_macro)/(mean_precision_score_cv_macro+mean_recall_score_cv_macro)\n",
    "f1_score_cv_weighted=(2*mean_precision_score_cv_weighted*mean_recall_score_cv_weighted)/(mean_precision_score_cv_weighted+mean_recall_score_cv_weighted)\n",
    "\n",
    "print(\"CV SKLEARN.METRICS RMSE:    \",mean_rmse_score_cv)\n",
    "print(\"CV SKLEARN.METRICS MAE:    \",mean_mae_score_cv)\n",
    "print(\"CV SKLEARN.METRICS MAP:    \", mean_map_score_cv)\n",
    "print(\"CV SKLEARN.METRICS NDCG:    \", mean_ndcg_score_cv)\n",
    "print(\"CV SKLEARN.METRICS PRECISION:    \",mean_precision_score_cv_micro,\"|\",\n",
    "                      mean_precision_score_cv_macro, \"|\", mean_precision_score_cv_weighted)\n",
    "print(\"CV SKLEARN.METRICS RECALL:    \",mean_recall_score_cv_micro,\"|\",\n",
    "                      mean_recall_score_cv_macro, \"|\", mean_recall_score_cv_weighted)\n",
    "print(\"CV SKLEARN.METRICS F1:   \", f1_score_cv_micro,\"|\",\n",
    "                      f1_score_cv_macro, \"|\", f1_score_cv_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7eeb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-TEST-TRAIN-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36e7f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "TRAIN-TEST SKLEARN.METRICS RMSE: 0.09941102803969593\n",
      "TRAIN-TEST SKLEARN.METRICS MAE: 0.013430588558381062\n",
      "TRAIN-TEST SKLEARN.METRICS NDCG: 0.6350113852030178\n",
      "TRAIN-TEST SKLEARN.METRICS MAP: 0.03266813056636299\n",
      "TRAIN-TEST SKLEARN.METRICS PRECISION:     0.9725825793088412 | 0.5307288463932868 | 0.9820160579274213\n",
      "TRAIN-TEST SKLEARN.METRICS RECALL:     0.9725825793088412 | 0.5615294280721956 | 0.9725825793088412\n",
      "TRAIN-TEST SKLEARN.METRICS F1:    0.9725825793088412 | 0.5456948645639333 | 0.9772765542210955\n"
     ]
    }
   ],
   "source": [
    "trainset_tt, testset_tt = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "algo_tt = KNNBasic()\n",
    "algo_tt.fit(trainset_tt)                     #UCENJE\n",
    "predictions_tt = algo_tt.test(testset_tt)    #PREDVIĐANJE NA TEST DATA\n",
    "\n",
    "dframe_tt = pd.DataFrame(predictions_tt, columns=[\"uid\", \"iid\", \"true_r\", \"est\", \"details\"])\n",
    "\n",
    "#EVALUACIJA\n",
    "\n",
    "average_rmse_TT=sqrt(mean_squared_error(dframe_tt['est'], dframe_tt['true_r']))\n",
    "average_mae_TT=(mean_absolute_error(dframe_tt['est'], dframe_tt['true_r']))\n",
    "average_ndcg_tt=ndcg_score(dframe_tt['true_r'].values.reshape(1, -1), dframe_tt['est'].values.reshape(1, -1))\n",
    "average_map_tt=average_precision_score(dframe_tt['true_r'].values, dframe_tt['est'].values)\n",
    "\n",
    "print('TRAIN-TEST SKLEARN.METRICS RMSE: ' + str(average_rmse_TT))\n",
    "print('TRAIN-TEST SKLEARN.METRICS MAE: ' + str(average_mae_TT))\n",
    "print('TRAIN-TEST SKLEARN.METRICS NDCG: ' + str(average_ndcg_tt))\n",
    "print('TRAIN-TEST SKLEARN.METRICS MAP: ' + str(average_map_tt))\n",
    "\n",
    "df_tt=dframe_tt.copy()\n",
    "df_tt.loc[df_tt['est']>=average_100th, 'est']=1\n",
    "df_tt.loc[df_tt['est']<average_100th, 'est']=0\n",
    "\n",
    "average_precision_tt_micro=(precision_score(df_tt['true_r'], df_tt['est'], average='micro'))\n",
    "average_precision_tt_macro=(precision_score(df_tt['true_r'], df_tt['est'], average='macro'))\n",
    "average_precision_tt_weighted=(precision_score(df_tt['true_r'], df_tt['est'], average='weighted'))\n",
    "\n",
    "average_recall_tt_micro=(recall_score(df_tt['true_r'], df_tt['est'], average='micro'))\n",
    "average_recall_tt_macro=(recall_score(df_tt['true_r'], df_tt['est'], average='macro'))\n",
    "average_recall_tt_weighted=(recall_score(df_tt['true_r'], df_tt['est'], average='weighted'))\n",
    "\n",
    "average_f1_tt_micro=(2*average_precision_tt_micro*average_recall_tt_micro)/(average_precision_tt_micro+average_recall_tt_micro)\n",
    "average_f1_tt_macro=(2*average_precision_tt_macro*average_recall_tt_macro)/(average_precision_tt_macro+average_recall_tt_macro)\n",
    "average_f1_tt_weighted=(2*average_precision_tt_weighted*average_recall_tt_weighted)/(average_precision_tt_weighted+average_recall_tt_weighted)\n",
    "\n",
    "\n",
    "print(\"TRAIN-TEST SKLEARN.METRICS PRECISION:    \", average_precision_tt_micro, \"|\",average_precision_tt_macro, \"|\",average_precision_tt_weighted)\n",
    "print(\"TRAIN-TEST SKLEARN.METRICS RECALL:    \", average_recall_tt_micro,\"|\",average_recall_tt_macro,\"|\",average_recall_tt_weighted)   \n",
    "print(\"TRAIN-TEST SKLEARN.METRICS F1:   \",average_f1_tt_micro ,\"|\", average_f1_tt_macro,\"|\", average_f1_tt_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b30a79c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION-NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION\n"
     ]
    }
   ],
   "source": [
    "print(\"NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION-NOVELTY-CATALOG COVERAGE-PREDICTION COVERAGE-PERSONALIZATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b57757fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOVELTY SCORE:    6.838314647706512\n"
     ]
    }
   ],
   "source": [
    "#EVALUACIJA NOVELTY\n",
    "def novelty(predicted: dict, pop: dict, u: int, n: int) -> (float, list):\n",
    "    \n",
    "    mean_self_information = []\n",
    "    k = 0\n",
    "    for pred100 in predicted: \n",
    "        self_information = 0\n",
    "        k += 1\n",
    "        for track_index in predicted[pred100].index:\n",
    "            self_information += np.sum(-np.log2(pop[track_index]/u))\n",
    "        mean_self_information.append(self_information/n)\n",
    "    novelty = sum(mean_self_information)/k\n",
    "    return novelty, mean_self_information\n",
    "    \n",
    "test_users = len(playlist_tracks_df) # Total unique users from notebook demo\n",
    "test_recs_per_user = 100\n",
    "# WHEN metrics.novelty is run\n",
    "novelty_score, _ = novelty(\n",
    "            predicted = preds_dict_rec_100,#predicted data\n",
    "            pop = items_count_dict, #test data\n",
    "            u = test_users, #broj korisnika\n",
    "            n = test_recs_per_user #broj testnih recorda\n",
    ")\n",
    "\n",
    "print(\"NOVELTY SCORE:   \",novelty_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9778bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATALOG COVERAGE SCORE:    0.07\n"
     ]
    }
   ],
   "source": [
    "#EVALUACIJA CATALOG COVERAGE\n",
    "def catalog_coverage(catalog: dict) -> float:\n",
    "    sum_non_zero=0\n",
    "    for elem in catalog:\n",
    "        if(catalog[elem]!=0):\n",
    "            sum_non_zero+=1\n",
    "    catalog_coverage = round(sum_non_zero/(len(catalog)*1.0),2)\n",
    "    return catalog_coverage\n",
    "catalog_coverage = catalog_coverage(\n",
    "    catalog = items_count_dict, #test data\n",
    ")\n",
    "\n",
    "print(\"CATALOG COVERAGE SCORE:   \",catalog_coverage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a79179f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONALIZATION SCORE:     0.23293794099163367\n"
     ]
    }
   ],
   "source": [
    "def personalization(predicted: List[list]) -> float:\n",
    "\n",
    "    def make_rec_matrix(predicted: List[list]) -> sp.csr_matrix:\n",
    "        df = pd.DataFrame(data=predicted).reset_index().melt(\n",
    "            id_vars='index', value_name='item',\n",
    "        )\n",
    "        df = df[['index', 'item']].pivot(index='index', columns='item', values='item')\n",
    "        df = pd.notna(df)*1\n",
    "        rec_matrix = sp.csr_matrix(df.values)\n",
    "        return rec_matrix\n",
    "\n",
    "    #create matrix for recommendations\n",
    "    predicted = np.array(predicted)\n",
    "    rec_matrix_sparse = make_rec_matrix(predicted)\n",
    "\n",
    "    #calculate similarity for every user's recommendation list\n",
    "    similarity = cosine_similarity(X=rec_matrix_sparse, dense_output=False)\n",
    "\n",
    "    #calculate average similarity\n",
    "    dim = similarity.shape[0]\n",
    "    personalization = (similarity.sum() - dim) / (dim * (dim - 1))\n",
    "    return 1-personalization\n",
    "\n",
    "pred100_list = [preds_dict_rec_100[playlist].index.tolist() for playlist in preds_dict_rec_100]\n",
    "\n",
    "# WHEN metrics.personalization is run\n",
    "personalization_score =personalization(\n",
    "    predicted=pred100_list)\n",
    "\n",
    "# THEN the personalization score should be within the expected value\n",
    "print(\"PERSONALIZATION SCORE:    \",personalization_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c75ff373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-List Diversity Score: 0.013408274261426394\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(dframe, average_100th):\n",
    "    index_rating = dframe[dframe['rating']==0].index\n",
    "    index_pred = dframe[dframe['pred']>average_100th].index\n",
    "    intersection_size = len(index_rating[index_rating.isin(index_pred)])\n",
    "    union_size = len(index_rating.union(index_pred))\n",
    "    return intersection_size / union_size if union_size != 0 else 0.0\n",
    "\n",
    "def inter_list_diversity(dframe, average_100th):\n",
    "    length_frame = len(dframe)\n",
    "    pairwise_similarities = []    \n",
    "    similarity = jaccard_similarity(dframe, average_100th)    \n",
    "    return similarity\n",
    "\n",
    "diversity_score = inter_list_diversity(ui_rating_prediction_df,average_100th)\n",
    "print(\"Inter-List Diversity Score:\", diversity_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
